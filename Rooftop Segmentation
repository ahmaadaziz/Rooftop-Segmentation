{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP/5dX3KoU7fZjp3RfBHbgX"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Detectron2\n\n!pip install torch torchvision\n\n!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gz3__Z6nwGqk","executionInfo":{"status":"ok","timestamp":1731576291999,"user_tz":-300,"elapsed":159489,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"575eb149-d9e8-4aae-9842-99edb534b54e","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-l9rg95xu\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-l9rg95xu\n","  Resolved https://github.com/facebookresearch/detectron2.git to commit 9131ce0e5bc0c89904541bc0355d933ccd6acbfb\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n","Collecting yacs>=0.1.8 (from detectron2==0.6)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.0)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting hydra-core>=1.1 (from detectron2==0.6)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black (from detectron2==0.6)\n","  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n","Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.2)\n","Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.67.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n","Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n","  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=5974639 sha256=15582c825e1235d636e5eec473a49d70a282a959702572c540ff0db78220b53c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-t5kg0yy4/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=8e837427afa97f0d3dfeb57ddecfd11f7be314963b69e78256019e0ea16f9e6b\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=5258a1ab5ba27a8ffad96caf7f01a41028d986d1cc92a6b0bf627a367c58e0ed\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built detectron2 fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n","Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-2.10.1 yacs-0.1.8\n"]}],"execution_count":1},{"cell_type":"code","source":"from google.colab import drive\n\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jKx3HXCwPNTO","executionInfo":{"status":"ok","timestamp":1731576440158,"user_tz":-300,"elapsed":28826,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"d5e037c9-679b-4aad-c7cd-2c40e493be8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"execution_count":2},{"cell_type":"code","source":"import zipfile\n\nimport os\n\n\n\n# Replace with your path to the dataset in Google Drive\n\nzip_path = '/content/drive/MyDrive/dataset.zip'\n\nunzip_path = '/content/dataset'\n\n\n\n# Unzip the dataset\n\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n\n    zip_ref.extractall(unzip_path)\n\n\n\n# Verify dataset contents\n\nprint(\"Files in dataset:\", os.listdir(unzip_path))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_piApQXGwJyU","executionInfo":{"status":"ok","timestamp":1731580462424,"user_tz":-300,"elapsed":74618,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"0fb81088-2a24-488d-9704-828e2c75b561"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files in dataset: ['content']\n"]}],"execution_count":15},{"cell_type":"code","source":"# prompt: move the folder assets and the file annotations.json from /content/dataset/content/dataset to /content/dataset\n\n\n\nimport shutil\n\n\n\n# Move the 'assets' folder\n\nsource_assets_folder = '/content/dataset/content/dataset/assets'\n\ndestination_assets_folder = '/content/dataset'\n\nshutil.move(source_assets_folder, destination_assets_folder)\n\n\n\n# Move the 'annotations.json' file\n\nsource_annotations_file = '/content/dataset/content/dataset/annotations.json'\n\ndestination_annotations_file = '/content/dataset'\n\nshutil.move(source_annotations_file, destination_annotations_file)\n\n\n\n# Verify the move operation\n\nprint(\"Files in dataset:\", os.listdir('/content/dataset'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WyI2_RrTnWme","executionInfo":{"status":"ok","timestamp":1731580529005,"user_tz":-300,"elapsed":353,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"df1ff766-a0b2-440e-9312-f4184a3043d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files in dataset: ['annotations.json', 'content', 'assets']\n"]}],"execution_count":16},{"cell_type":"code","source":"# prompt: delete the file annotations.json in /content/dataset and then copy the file annotations.json from /content/drive/MyDrive to the place where you deleted from before\n\n\n\n# Delete annotations.json in /content/dataset if it exists\n\nannotations_path = \"/content/dataset/annotations.json\"\n\nif os.path.exists(annotations_path):\n\n  os.remove(annotations_path)\n\n  print(f\"Deleted: {annotations_path}\")\n\nelse:\n\n  print(f\"File not found: {annotations_path}\")\n\n\n\n# Copy annotations.json from /content/drive/MyDrive to /content/dataset\n\nsource_annotations_file = \"/content/drive/MyDrive/annotations.json\"\n\ndestination_annotations_file = \"/content/dataset/annotations.json\"\n\n\n\nif os.path.exists(source_annotations_file):\n\n    shutil.copy2(source_annotations_file, destination_annotations_file) # Use copy2 to preserve metadata\n\n    print(f\"Copied: {source_annotations_file} to {destination_annotations_file}\")\n\nelse:\n\n    print(f\"Source file not found: {source_annotations_file}\")\n\n\n\n# Verify the copy operation\n\nprint(\"Files in dataset:\", os.listdir('/content/dataset'))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1-RNo4IQDUX","executionInfo":{"status":"ok","timestamp":1731580693972,"user_tz":-300,"elapsed":1118,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"0b86361d-ade9-46b4-a599-c30162454660"},"outputs":[{"output_type":"stream","name":"stdout","text":["Deleted: /content/dataset/annotations.json\n","Copied: /content/drive/MyDrive/annotations.json to /content/dataset/annotations.json\n","Files in dataset: ['annotations.json', 'content', 'assets']\n"]}],"execution_count":17},{"cell_type":"code","source":"import json\n\nfrom collections import defaultdict\n\n\n\n# Path to your COCO JSON file\n\nannotation_path = \"/content/dataset/annotations.json\"  # Update with your actual path\n\n\n\n# Load the JSON data\n\nwith open(annotation_path, 'r') as f:\n\n    coco_data = json.load(f)\n\n\n\n# Dictionary to store counts for each category\n\ncategory_usage = defaultdict(int)\n\n\n\n# Build a dictionary with category IDs and names\n\ncategory_names = {cat['id']: cat['name'] for cat in coco_data['categories']}\n\n\n\n# Count category usage in annotations\n\nfor annotation in coco_data['annotations']:\n\n    category_id = annotation['category_id']\n\n    category_usage[category_names[category_id]] += 1\n\n\n\n# Print out the usage summary\n\nprint(\"Category usage in the dataset:\")\n\nfor category, count in category_usage.items():\n\n    print(f\"{category}: {count} occurrences\")\n\n\n\n# Find and list categories that are not used\n\nunused_categories = [cat['name'] for cat in coco_data['categories'] if cat['name'] not in category_usage]\n\nif unused_categories:\n\n    print(\"\\nCategories not used in any annotation:\")\n\n    for category in unused_categories:\n\n        print(category)\n\nelse:\n\n    print(\"\\nAll categories are used in the annotations.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFLYvLe_41u8","executionInfo":{"status":"ok","timestamp":1731580735694,"user_tz":-300,"elapsed":368,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"6b2c428c-a3e2-45bd-92a2-b49a311f8b0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Category usage in the dataset:\n","roof: 210 occurrences\n","skylight: 330 occurrences\n","air vent: 44 occurrences\n","antenna: 22 occurrences\n","plumbing vent: 57 occurrences\n","chimney: 77 occurrences\n","solars: 60 occurrences\n","Radiator: 13 occurrences\n","window: 90 occurrences\n","coolers: 6 occurrences\n","ladder: 4 occurrences\n","ventilation: 3 occurrences\n","\n","All categories are used in the annotations.\n"]}],"execution_count":18},{"cell_type":"code","source":"import json\n\n\n\n# Path to your COCO JSON file\n\nannotation_path = \"/content/dataset/annotations.json\"  # Replace with your actual path\n\n\n\n# Load the JSON data\n\nwith open(annotation_path, 'r') as f:\n\n    coco_data = json.load(f)\n\n\n\n# Extract the unique category names\n\ncategory_names = [category['name'] for category in coco_data['categories']]\n\n\n\n# Print to confirm\n\nprint(\"Extracted categories:\", category_names)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amNcRelXjIRf","executionInfo":{"status":"ok","timestamp":1731581379543,"user_tz":-300,"elapsed":716,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"7f36284e-c071-4568-e753-b3e6f0826325"},"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted categories: ['roof', 'skylight', 'air vent', 'antenna', 'plumbing vent', 'chimney', 'solars', 'Radiator', 'window', 'coolers', 'ladder', 'ventilation']\n"]}],"execution_count":22},{"cell_type":"code","source":"from PIL import Image\n\nImage.MAX_IMAGE_PIXELS = None  # Disable DecompressionBombError check\n","metadata":{"id":"1OsCpow7pjUq","executionInfo":{"status":"ok","timestamp":1731581391572,"user_tz":-300,"elapsed":709,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from detectron2.config import get_cfg\n\nfrom detectron2.engine import DefaultTrainer\n\nfrom detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader\n\nfrom detectron2.data.datasets import register_coco_instances\n\nfrom detectron2 import model_zoo\n\nfrom detectron2.data import transforms as T\n\nimport os\n\n\n\n# Register the dataset\n\ndataset_path = '/content/dataset'  # Path to unzipped dataset folder\n\nregister_coco_instances(\"custom_train\", {}, f\"{dataset_path}/annotations.json\", f\"{dataset_path}/assets\")\n\n\n\nMetadataCatalog.get(\"custom_train\").thing_classes = category_names\n\n\n\n# Custom trainer with data augmentation and checkpointing\n\nclass CustomTrainer(DefaultTrainer):\n\n    @classmethod\n\n    def build_train_loader(cls, cfg):\n\n        # Add basic augmentations: random flip and color jitter\n\n        augmentation = [\n\n            T.RandomFlip(horizontal=True, vertical=False),\n\n            T.RandomBrightness(0.8, 1.2),\n\n            T.RandomContrast(0.8, 1.2),\n\n            T.RandomSaturation(0.8, 1.2)\n\n        ]\n\n        return build_detection_train_loader(cfg, mapper=T.DatasetMapper(cfg, is_train=True, augmentations=augmentation))\n\n\n\n# Set up configuration for training\n\ncfg = get_cfg()\n\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n\ncfg.DATASETS.TRAIN = (\"custom_train\",)\n\ncfg.DATASETS.TEST = ()\n\ncfg.DATALOADER.NUM_WORKERS = 1\n\n\n\n# Model and training hyperparameters\n\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n\ncfg.SOLVER.IMS_PER_BATCH = 1\n\ncfg.SOLVER.BASE_LR = 0.001  # Lower initial learning rate\n\ncfg.SOLVER.MAX_ITER = 1500  # More iterations\n\ncfg.SOLVER.STEPS = []  # Disable learning rate decay\n\ncfg.SOLVER.CHECKPOINT_PERIOD = 50  # Save checkpoint every 50 iterations\n\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(category_names)  # Set the number of classes\n\n\n\n# Output directory\n\ncfg.OUTPUT_DIR = \"/content/output\"\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n\n\n\n# # Set up configuration for training\n\n# cfg = get_cfg()\n\n# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n\n# cfg.DATASETS.TRAIN = (\"custom_train\",)\n\n# cfg.DATASETS.TEST = ()\n\n# cfg.DATALOADER.NUM_WORKERS = 1  # Decrease number of workers\n\n\n\n# # Adjust the batch size\n\n# cfg.SOLVER.IMS_PER_BATCH = 1  # Set to 1 or another small value based on memory\n\n# # cfg.DATALOADER.NUM_WORKERS = 2\n\n# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Load pretrained weights\n\n# # cfg.SOLVER.IMS_PER_BATCH = 2\n\n# cfg.SOLVER.BASE_LR = 0.0025  # Initial learning rate\n\n# cfg.SOLVER.MAX_ITER = 1000  # Increase this if you want more epochs\n\n# cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(category_names)  # Set the number of classes\n\n\n\n# # Set output directory\n\n# cfg.OUTPUT_DIR = \"/content/output\"\n\n# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","metadata":{"id":"e0kdxjcswQgy","executionInfo":{"status":"ok","timestamp":1731581639910,"user_tz":-300,"elapsed":713,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Train with custom trainer\n\ntrainer = CustomTrainer(cfg)\n\ntrainer.resume_or_load(resume=False)\n\ntrainer.train()","metadata":{"id":"U0sOEdWjwTK6","colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"status":"error","timestamp":1731581868163,"user_tz":-300,"elapsed":2732,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"bfb3733a-f102-42a2-f413-f3ba2bf6abc2"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-ce8fc39009fd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train with custom trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# Assume these objects must be constructed in this order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \"\"\"\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/modeling/meta_arch/build.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmeta_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETA_ARCHITECTURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETA_ARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0m_log_api_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"modeling.meta_arch.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}],"execution_count":27},{"cell_type":"code","source":"import shutil\n\n\n\n# Ensure that Google Drive is mounted before running this\n\n# Copy the trained model to Google Drive\n\nshutil.copy(\"/content/output/model_final.pth\", \"/content/drive/MyDrive/model_final.pth\")\n\nshutil.copy(\"/content/dataset/annotations.json\", \"/content/drive/MyDrive/annotations.json\")\n\nprint(\"Model saved successfully.\")","metadata":{"id":"gn93ABCUwVX5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731529998224,"user_tz":-300,"elapsed":1919,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"de5433b0-8f3e-428b-f55a-9f923c7be153"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved successfully.\n"]}],"execution_count":null},{"cell_type":"markdown","source":"FROM HERE ON THE MODEL IS BEING TESTED","metadata":{"id":"ab7K8tTLADiv"}},{"cell_type":"code","source":"import torch\n\nfrom detectron2.engine import DefaultPredictor\n\nfrom detectron2.config import get_cfg\n\nfrom detectron2.data import MetadataCatalog\n\nfrom detectron2.utils.visualizer import Visualizer\n\nimport cv2\n\nimport matplotlib.pyplot as plt\n\nfrom detectron2 import model_zoo\n\n\n\n# Set up custom class names (must match the ones used during training)\n\ncategory_names = ['roof', 'skylight', 'air vent', 'antenna', 'plumbing vent',\n\n                  'chimney', 'solars', 'Radiator', 'window', 'coolers',\n\n                  'ladder', 'ventilation']\n\nnum_classes = len(category_names)\n\n\n\n# Set up configuration for inference\n\ncfg = get_cfg()\n\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # Number of classes (excluding background)\n\ncfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/model_final.pth\"  # Path to your fine-tuned model\n\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set a threshold for predictions\n\ncfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n\n# Register metadata for the model\n\nMetadataCatalog.get(\"custom_test\").thing_classes = category_names\n\n\n\n# Initialize the predictor\n\npredictor = DefaultPredictor(cfg)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9NVGJgHfIwja","executionInfo":{"status":"ok","timestamp":1731578818997,"user_tz":-300,"elapsed":3700,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"ae83c0dc-e67d-4c17-8264-efee28311153"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(f, map_location=torch.device(\"cpu\"))\n"]}],"execution_count":11},{"cell_type":"code","source":"print(MetadataCatalog.get(\"custom_train\").thing_classes)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ia1q0rPCH15j","executionInfo":{"status":"ok","timestamp":1731578835366,"user_tz":-300,"elapsed":519,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"4bd8d413-fe2d-4a6f-a394-bfaa4d22615a"},"outputs":[{"output_type":"stream","name":"stdout","text":["['roof', 'skylight', 'air vent', 'antenna', 'plumbing vent', 'chimney', 'solars', 'Radiator', 'window', 'coolers', 'ladder', 'ventilation']\n"]}],"execution_count":12},{"cell_type":"code","source":"# Load an image\n\nimage_path = \"/content/Orthomosaic.jpg\"  # Replace with the path to your test image\n\nimage = cv2.imread(image_path)\n\n\n\n# Perform inference\n\noutputs = predictor(image)\n\n\n\n# Visualize the predictions\n\nv = Visualizer(image[:, :, ::-1], MetadataCatalog.get(\"custom_test\"), scale=1.2)\n\nout = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n\n\n# Display the result\n\nplt.figure(figsize=(12, 12))\n\nplt.imshow(out.get_image()[:, :, ::-1])\n\nplt.axis(\"off\")\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":892,"output_embedded_package_id":"1xkibOVWfUp_hxS90d0NZOaF4tMoxJCn0"},"id":"Ssu46x0HEaD9","executionInfo":{"status":"ok","timestamp":1731578904739,"user_tz":-300,"elapsed":45730,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"3adca5c7-6286-48ed-9d1d-0e76a420fe3d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Print predicted classes and scores\n\npred_classes = outputs[\"instances\"].pred_classes\n\npred_scores = outputs[\"instances\"].scores\n\nprint(\"Predicted Classes:\", pred_classes)\n\nprint(\"Predicted Scores:\", pred_scores)\n\n\n\n# Map predicted class IDs to category names\n\npredicted_class_names = [category_names[i] for i in pred_classes.cpu().numpy()]\n\nprint(\"Predicted Class Names:\", predicted_class_names)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ALA2JC7H9Tr","executionInfo":{"status":"ok","timestamp":1731578928424,"user_tz":-300,"elapsed":503,"user":{"displayName":"Ahmad aziz","userId":"16175101896276090451"}},"outputId":"31e73359-9ee8-42d6-9005-26131705fb6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Classes: tensor([0, 0])\n","Predicted Scores: tensor([0.9494, 0.5327])\n","Predicted Class Names: ['roof', 'roof']\n"]}],"execution_count":14}]}